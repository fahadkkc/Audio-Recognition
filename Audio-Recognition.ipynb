{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259659a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a92a9133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2393b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.4.4)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from sounddevice) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d11dd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (2.6.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: cached-property in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (59.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f4442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wavio in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from wavio) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install wavio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d65deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd5dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from scipy) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb1e7efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e355773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (4.63.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-resources->tqdm) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e98dbd55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (1.19.5)\n",
      "Requirement already satisfied: decorator>=4.0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: audioread>=2.1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (1.5.4)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (0.24.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from numba>=0.45.1->librosa) (0.36.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from numba>=0.45.1->librosa) (59.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from packaging>=20.0->librosa) (3.0.7)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038b34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bc2ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a123cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(filename2, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a0bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 1.Get file names from directory\n",
    "file_list=os.listdir(r\"Dilip/\")\n",
    "file_list2=os.listdir(r\"Rushitha/\")\n",
    "file_list3=os.listdir(r\"Deepika/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f33759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features\n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "temp='Dilip/'\n",
    "filename2='Dilip/'\n",
    "for i in range(len(file_list)):\n",
    "    filename2=filename2+file_list[i]\n",
    "    final_class_labels='Dilip'\n",
    "    data=features_extractor(filename2)\n",
    "    filename2=temp\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b750bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-373.43033, 98.91888, -27.696129, 36.301384, ...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-366.42926, 96.7193, -26.216177, 41.29728, 6....</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-386.0906, 91.45142, -28.100079, 24.620644, -...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-446.76642, 78.468796, -26.192389, 26.76531, ...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-393.14233, 87.91409, -22.029213, 30.32416, 6...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-447.30093, 70.72171, -17.304922, 23.608818, ...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-433.13803, 77.93451, -34.303345, 27.240461, ...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-441.1718, 73.05308, -20.919064, 17.411348, 1...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-424.51932, 73.80594, -17.079762, 23.58509, 1...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-360.33038, 91.111725, -13.313395, 39.410934,...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-420.54095, 86.8513, -28.25004, 30.182877, 0....</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-415.53458, 94.5676, -20.089699, 25.266714, -...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-390.3427, 94.63815, -28.637346, 39.069004, 9...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature  class\n",
       "0   [-373.43033, 98.91888, -27.696129, 36.301384, ...  Dilip\n",
       "1   [-366.42926, 96.7193, -26.216177, 41.29728, 6....  Dilip\n",
       "2   [-386.0906, 91.45142, -28.100079, 24.620644, -...  Dilip\n",
       "3   [-446.76642, 78.468796, -26.192389, 26.76531, ...  Dilip\n",
       "4   [-393.14233, 87.91409, -22.029213, 30.32416, 6...  Dilip\n",
       "5   [-447.30093, 70.72171, -17.304922, 23.608818, ...  Dilip\n",
       "6   [-433.13803, 77.93451, -34.303345, 27.240461, ...  Dilip\n",
       "7   [-441.1718, 73.05308, -20.919064, 17.411348, 1...  Dilip\n",
       "8   [-424.51932, 73.80594, -17.079762, 23.58509, 1...  Dilip\n",
       "9   [-360.33038, 91.111725, -13.313395, 39.410934,...  Dilip\n",
       "10  [-420.54095, 86.8513, -28.25004, 30.182877, 0....  Dilip\n",
       "11  [-415.53458, 94.5676, -20.089699, 25.266714, -...  Dilip\n",
       "12  [-390.3427, 94.63815, -28.637346, 39.069004, 9...  Dilip"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "Dilip_data=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "Dilip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdf7ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "temp='Rushitha/'\n",
    "filename2='Rushitha/'\n",
    "for i in range(len(file_list2)):\n",
    "    filename2=filename2+file_list2[i]\n",
    "    final_class_labels='Rushitha'\n",
    "    data=features_extractor(filename2)\n",
    "    filename2=temp\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47714507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-404.02756, 89.62253, 33.486397, 55.524853, 2...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-343.57275, 89.36185, 24.55968, 40.007652, -4...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-346.79266, 92.725075, 14.128695, 46.267902, ...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-352.82776, 94.983635, 25.44872, 47.39207, 2....</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-385.31918, 84.54665, 25.746578, 52.334724, 1...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-416.0064, 75.76176, 25.899006, 63.606525, 23...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-390.7475, 80.451385, 27.800024, 48.352486, 1...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-395.1109, 81.72232, 21.50955, 60.33184, 20.4...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-378.944, 80.52878, 25.204329, 53.926613, 12....</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-368.4545, 81.391106, 29.650213, 45.270844, 7...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-386.5068, 94.56663, 25.87882, 53.421253, 20....</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-384.34183, 90.25247, 34.102463, 56.186333, 2...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-375.9678, 93.48844, 28.51567, 50.25309, 13.1...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-388.37595, 100.85277, 26.474802, 62.199562, ...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-376.19104, 89.29606, 27.970118, 49.152122, 1...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-392.8989, 101.4514, 25.310928, 41.558876, 10...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-397.4, 97.371704, 26.052332, 43.38701, 9.001...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[-299.0971, 105.57275, 20.759405, 45.57693, 2....</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-325.5754, 77.42181, 30.56321, 42.67238, 0.90...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature     class\n",
       "0   [-404.02756, 89.62253, 33.486397, 55.524853, 2...  Rushitha\n",
       "1   [-343.57275, 89.36185, 24.55968, 40.007652, -4...  Rushitha\n",
       "2   [-346.79266, 92.725075, 14.128695, 46.267902, ...  Rushitha\n",
       "3   [-352.82776, 94.983635, 25.44872, 47.39207, 2....  Rushitha\n",
       "4   [-385.31918, 84.54665, 25.746578, 52.334724, 1...  Rushitha\n",
       "5   [-416.0064, 75.76176, 25.899006, 63.606525, 23...  Rushitha\n",
       "6   [-390.7475, 80.451385, 27.800024, 48.352486, 1...  Rushitha\n",
       "7   [-395.1109, 81.72232, 21.50955, 60.33184, 20.4...  Rushitha\n",
       "8   [-378.944, 80.52878, 25.204329, 53.926613, 12....  Rushitha\n",
       "9   [-368.4545, 81.391106, 29.650213, 45.270844, 7...  Rushitha\n",
       "10  [-386.5068, 94.56663, 25.87882, 53.421253, 20....  Rushitha\n",
       "11  [-384.34183, 90.25247, 34.102463, 56.186333, 2...  Rushitha\n",
       "12  [-375.9678, 93.48844, 28.51567, 50.25309, 13.1...  Rushitha\n",
       "13  [-388.37595, 100.85277, 26.474802, 62.199562, ...  Rushitha\n",
       "14  [-376.19104, 89.29606, 27.970118, 49.152122, 1...  Rushitha\n",
       "15  [-392.8989, 101.4514, 25.310928, 41.558876, 10...  Rushitha\n",
       "16  [-397.4, 97.371704, 26.052332, 43.38701, 9.001...  Rushitha\n",
       "17  [-299.0971, 105.57275, 20.759405, 45.57693, 2....  Rushitha\n",
       "18  [-325.5754, 77.42181, 30.56321, 42.67238, 0.90...  Rushitha"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "Rushita_data=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "Rushita_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0259a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features=[]\n",
    "temp='Deepika/'\n",
    "filename2='Deepika/'\n",
    "for i in range(len(file_list3)):\n",
    "    filename2=filename2+file_list3[i]\n",
    "    final_class_labels='Deepika'\n",
    "    data=features_extractor(filename2)\n",
    "    filename2=temp\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbb154cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-491.65817, 81.80313, 11.075409, 31.186995, 6...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-526.21277, 96.57279, 9.111094, 33.2841, -2.8...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-521.4755, 88.11082, 4.689987, 29.459574, 10....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-544.6688, 84.87762, 13.337404, 30.462145, 6....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-522.4939, 99.796005, 8.622728, 37.004143, 12...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-487.3861, 100.86176, 5.985469, 16.346087, -0...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-453.8572, 112.415115, 9.502748, 9.912313, -1...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-427.275, 110.01141, 4.894287, 31.479185, -4....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-432.07138, 109.01962, 9.06097, 18.56485, -6....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-426.90106, 117.280815, -4.033839, 13.470641,...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-414.26892, 115.32382, -14.838806, 20.379574,...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-491.07474, 97.5314, 7.5555596, 29.793596, 1....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-409.6101, 102.8034, -1.0486282, 16.289116, -...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-499.72113, 97.15009, 14.821616, 30.136734, -...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-484.67276, 99.192, 7.3871603, 31.257933, -16...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-513.3537, 97.526855, 16.037735, 22.774244, 2...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-509.0029, 109.47156, 12.1964655, 36.742676, ...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[-544.54004, 95.800255, 10.380386, 27.163668, ...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-539.9736, 92.22041, 19.046373, 35.36793, 4.0...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[-518.1061, 105.35859, 8.754209, 33.060467, 2....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature    class\n",
       "0   [-491.65817, 81.80313, 11.075409, 31.186995, 6...  Deepika\n",
       "1   [-526.21277, 96.57279, 9.111094, 33.2841, -2.8...  Deepika\n",
       "2   [-521.4755, 88.11082, 4.689987, 29.459574, 10....  Deepika\n",
       "3   [-544.6688, 84.87762, 13.337404, 30.462145, 6....  Deepika\n",
       "4   [-522.4939, 99.796005, 8.622728, 37.004143, 12...  Deepika\n",
       "5   [-487.3861, 100.86176, 5.985469, 16.346087, -0...  Deepika\n",
       "6   [-453.8572, 112.415115, 9.502748, 9.912313, -1...  Deepika\n",
       "7   [-427.275, 110.01141, 4.894287, 31.479185, -4....  Deepika\n",
       "8   [-432.07138, 109.01962, 9.06097, 18.56485, -6....  Deepika\n",
       "9   [-426.90106, 117.280815, -4.033839, 13.470641,...  Deepika\n",
       "10  [-414.26892, 115.32382, -14.838806, 20.379574,...  Deepika\n",
       "11  [-491.07474, 97.5314, 7.5555596, 29.793596, 1....  Deepika\n",
       "12  [-409.6101, 102.8034, -1.0486282, 16.289116, -...  Deepika\n",
       "13  [-499.72113, 97.15009, 14.821616, 30.136734, -...  Deepika\n",
       "14  [-484.67276, 99.192, 7.3871603, 31.257933, -16...  Deepika\n",
       "15  [-513.3537, 97.526855, 16.037735, 22.774244, 2...  Deepika\n",
       "16  [-509.0029, 109.47156, 12.1964655, 36.742676, ...  Deepika\n",
       "17  [-544.54004, 95.800255, 10.380386, 27.163668, ...  Deepika\n",
       "18  [-539.9736, 92.22041, 19.046373, 35.36793, 4.0...  Deepika\n",
       "19  [-518.1061, 105.35859, 8.754209, 33.060467, 2....  Deepika"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "Deepika_data=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "Deepika_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddcd39b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-373.43033, 98.91888, -27.696129, 36.301384, ...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-366.42926, 96.7193, -26.216177, 41.29728, 6....</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-386.0906, 91.45142, -28.100079, 24.620644, -...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-446.76642, 78.468796, -26.192389, 26.76531, ...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-393.14233, 87.91409, -22.029213, 30.32416, 6...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[-447.30093, 70.72171, -17.304922, 23.608818, ...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[-433.13803, 77.93451, -34.303345, 27.240461, ...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[-441.1718, 73.05308, -20.919064, 17.411348, 1...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[-424.51932, 73.80594, -17.079762, 23.58509, 1...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[-360.33038, 91.111725, -13.313395, 39.410934,...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[-420.54095, 86.8513, -28.25004, 30.182877, 0....</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[-415.53458, 94.5676, -20.089699, 25.266714, -...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[-390.3427, 94.63815, -28.637346, 39.069004, 9...</td>\n",
       "      <td>Dilip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>[-491.65817, 81.80313, 11.075409, 31.186995, 6...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>[-526.21277, 96.57279, 9.111094, 33.2841, -2.8...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>[-521.4755, 88.11082, 4.689987, 29.459574, 10....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>[-544.6688, 84.87762, 13.337404, 30.462145, 6....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>[-522.4939, 99.796005, 8.622728, 37.004143, 12...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>[-487.3861, 100.86176, 5.985469, 16.346087, -0...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>[-453.8572, 112.415115, 9.502748, 9.912313, -1...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>[-427.275, 110.01141, 4.894287, 31.479185, -4....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>[-432.07138, 109.01962, 9.06097, 18.56485, -6....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9</td>\n",
       "      <td>[-426.90106, 117.280815, -4.033839, 13.470641,...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>[-414.26892, 115.32382, -14.838806, 20.379574,...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>[-491.07474, 97.5314, 7.5555596, 29.793596, 1....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>[-409.6101, 102.8034, -1.0486282, 16.289116, -...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13</td>\n",
       "      <td>[-499.72113, 97.15009, 14.821616, 30.136734, -...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14</td>\n",
       "      <td>[-484.67276, 99.192, 7.3871603, 31.257933, -16...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>[-513.3537, 97.526855, 16.037735, 22.774244, 2...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>[-509.0029, 109.47156, 12.1964655, 36.742676, ...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17</td>\n",
       "      <td>[-544.54004, 95.800255, 10.380386, 27.163668, ...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>18</td>\n",
       "      <td>[-539.9736, 92.22041, 19.046373, 35.36793, 4.0...</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>19</td>\n",
       "      <td>[-518.1061, 105.35859, 8.754209, 33.060467, 2....</td>\n",
       "      <td>Deepika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>[-404.02756, 89.62253, 33.486397, 55.524853, 2...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>[-343.57275, 89.36185, 24.55968, 40.007652, -4...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>[-346.79266, 92.725075, 14.128695, 46.267902, ...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>[-352.82776, 94.983635, 25.44872, 47.39207, 2....</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>[-385.31918, 84.54665, 25.746578, 52.334724, 1...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>[-416.0064, 75.76176, 25.899006, 63.606525, 23...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6</td>\n",
       "      <td>[-390.7475, 80.451385, 27.800024, 48.352486, 1...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7</td>\n",
       "      <td>[-395.1109, 81.72232, 21.50955, 60.33184, 20.4...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>[-378.944, 80.52878, 25.204329, 53.926613, 12....</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>9</td>\n",
       "      <td>[-368.4545, 81.391106, 29.650213, 45.270844, 7...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10</td>\n",
       "      <td>[-386.5068, 94.56663, 25.87882, 53.421253, 20....</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>11</td>\n",
       "      <td>[-384.34183, 90.25247, 34.102463, 56.186333, 2...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12</td>\n",
       "      <td>[-375.9678, 93.48844, 28.51567, 50.25309, 13.1...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13</td>\n",
       "      <td>[-388.37595, 100.85277, 26.474802, 62.199562, ...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>14</td>\n",
       "      <td>[-376.19104, 89.29606, 27.970118, 49.152122, 1...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15</td>\n",
       "      <td>[-392.8989, 101.4514, 25.310928, 41.558876, 10...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>16</td>\n",
       "      <td>[-397.4, 97.371704, 26.052332, 43.38701, 9.001...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>17</td>\n",
       "      <td>[-299.0971, 105.57275, 20.759405, 45.57693, 2....</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>18</td>\n",
       "      <td>[-325.5754, 77.42181, 30.56321, 42.67238, 0.90...</td>\n",
       "      <td>Rushitha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                            feature     class\n",
       "0       0  [-373.43033, 98.91888, -27.696129, 36.301384, ...     Dilip\n",
       "1       1  [-366.42926, 96.7193, -26.216177, 41.29728, 6....     Dilip\n",
       "2       2  [-386.0906, 91.45142, -28.100079, 24.620644, -...     Dilip\n",
       "3       3  [-446.76642, 78.468796, -26.192389, 26.76531, ...     Dilip\n",
       "4       4  [-393.14233, 87.91409, -22.029213, 30.32416, 6...     Dilip\n",
       "5       5  [-447.30093, 70.72171, -17.304922, 23.608818, ...     Dilip\n",
       "6       6  [-433.13803, 77.93451, -34.303345, 27.240461, ...     Dilip\n",
       "7       7  [-441.1718, 73.05308, -20.919064, 17.411348, 1...     Dilip\n",
       "8       8  [-424.51932, 73.80594, -17.079762, 23.58509, 1...     Dilip\n",
       "9       9  [-360.33038, 91.111725, -13.313395, 39.410934,...     Dilip\n",
       "10     10  [-420.54095, 86.8513, -28.25004, 30.182877, 0....     Dilip\n",
       "11     11  [-415.53458, 94.5676, -20.089699, 25.266714, -...     Dilip\n",
       "12     12  [-390.3427, 94.63815, -28.637346, 39.069004, 9...     Dilip\n",
       "13      0  [-491.65817, 81.80313, 11.075409, 31.186995, 6...   Deepika\n",
       "14      1  [-526.21277, 96.57279, 9.111094, 33.2841, -2.8...   Deepika\n",
       "15      2  [-521.4755, 88.11082, 4.689987, 29.459574, 10....   Deepika\n",
       "16      3  [-544.6688, 84.87762, 13.337404, 30.462145, 6....   Deepika\n",
       "17      4  [-522.4939, 99.796005, 8.622728, 37.004143, 12...   Deepika\n",
       "18      5  [-487.3861, 100.86176, 5.985469, 16.346087, -0...   Deepika\n",
       "19      6  [-453.8572, 112.415115, 9.502748, 9.912313, -1...   Deepika\n",
       "20      7  [-427.275, 110.01141, 4.894287, 31.479185, -4....   Deepika\n",
       "21      8  [-432.07138, 109.01962, 9.06097, 18.56485, -6....   Deepika\n",
       "22      9  [-426.90106, 117.280815, -4.033839, 13.470641,...   Deepika\n",
       "23     10  [-414.26892, 115.32382, -14.838806, 20.379574,...   Deepika\n",
       "24     11  [-491.07474, 97.5314, 7.5555596, 29.793596, 1....   Deepika\n",
       "25     12  [-409.6101, 102.8034, -1.0486282, 16.289116, -...   Deepika\n",
       "26     13  [-499.72113, 97.15009, 14.821616, 30.136734, -...   Deepika\n",
       "27     14  [-484.67276, 99.192, 7.3871603, 31.257933, -16...   Deepika\n",
       "28     15  [-513.3537, 97.526855, 16.037735, 22.774244, 2...   Deepika\n",
       "29     16  [-509.0029, 109.47156, 12.1964655, 36.742676, ...   Deepika\n",
       "30     17  [-544.54004, 95.800255, 10.380386, 27.163668, ...   Deepika\n",
       "31     18  [-539.9736, 92.22041, 19.046373, 35.36793, 4.0...   Deepika\n",
       "32     19  [-518.1061, 105.35859, 8.754209, 33.060467, 2....   Deepika\n",
       "33      0  [-404.02756, 89.62253, 33.486397, 55.524853, 2...  Rushitha\n",
       "34      1  [-343.57275, 89.36185, 24.55968, 40.007652, -4...  Rushitha\n",
       "35      2  [-346.79266, 92.725075, 14.128695, 46.267902, ...  Rushitha\n",
       "36      3  [-352.82776, 94.983635, 25.44872, 47.39207, 2....  Rushitha\n",
       "37      4  [-385.31918, 84.54665, 25.746578, 52.334724, 1...  Rushitha\n",
       "38      5  [-416.0064, 75.76176, 25.899006, 63.606525, 23...  Rushitha\n",
       "39      6  [-390.7475, 80.451385, 27.800024, 48.352486, 1...  Rushitha\n",
       "40      7  [-395.1109, 81.72232, 21.50955, 60.33184, 20.4...  Rushitha\n",
       "41      8  [-378.944, 80.52878, 25.204329, 53.926613, 12....  Rushitha\n",
       "42      9  [-368.4545, 81.391106, 29.650213, 45.270844, 7...  Rushitha\n",
       "43     10  [-386.5068, 94.56663, 25.87882, 53.421253, 20....  Rushitha\n",
       "44     11  [-384.34183, 90.25247, 34.102463, 56.186333, 2...  Rushitha\n",
       "45     12  [-375.9678, 93.48844, 28.51567, 50.25309, 13.1...  Rushitha\n",
       "46     13  [-388.37595, 100.85277, 26.474802, 62.199562, ...  Rushitha\n",
       "47     14  [-376.19104, 89.29606, 27.970118, 49.152122, 1...  Rushitha\n",
       "48     15  [-392.8989, 101.4514, 25.310928, 41.558876, 10...  Rushitha\n",
       "49     16  [-397.4, 97.371704, 26.052332, 43.38701, 9.001...  Rushitha\n",
       "50     17  [-299.0971, 105.57275, 20.759405, 45.57693, 2....  Rushitha\n",
       "51     18  [-325.5754, 77.42181, 30.56321, 42.67238, 0.90...  Rushitha"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [Dilip_data, Deepika_data, Rushita_data]\n",
    "dataset = pd.concat(frames)\n",
    "dataset=dataset.reset_index(level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
    "#dataset=dataset.drop('index')\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a08cc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(dataset['feature'].tolist())\n",
    "y=np.array(dataset['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43a2d2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 40)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55066c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dilip', 'Dilip', 'Dilip', 'Dilip', 'Dilip', 'Dilip', 'Dilip',\n",
       "       'Dilip', 'Dilip', 'Dilip', 'Dilip', 'Dilip', 'Dilip', 'Deepika',\n",
       "       'Deepika', 'Deepika', 'Deepika', 'Deepika', 'Deepika', 'Deepika',\n",
       "       'Deepika', 'Deepika', 'Deepika', 'Deepika', 'Deepika', 'Deepika',\n",
       "       'Deepika', 'Deepika', 'Deepika', 'Deepika', 'Deepika', 'Deepika',\n",
       "       'Deepika', 'Rushitha', 'Rushitha', 'Rushitha', 'Rushitha',\n",
       "       'Rushitha', 'Rushitha', 'Rushitha', 'Rushitha', 'Rushitha',\n",
       "       'Rushitha', 'Rushitha', 'Rushitha', 'Rushitha', 'Rushitha',\n",
       "       'Rushitha', 'Rushitha', 'Rushitha', 'Rushitha', 'Rushitha'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "488d85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "###y=np.array(pd.get_dummies(y))\n",
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5372c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "253f26be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 40)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6caf48ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e241ace6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd76f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79116fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6efb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c22b3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "### No of classes\n",
    "num_labels=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d50ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4da87fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 303       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 44,703\n",
      "Trainable params: 44,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a0f0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eecbac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "2/2 [==============================] - 1s 231ms/step - loss: 66.7746 - accuracy: 0.2439 - val_loss: 9.9088 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.90881, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 2/90\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 61.0661 - accuracy: 0.3659 - val_loss: 21.4373 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 9.90881\n",
      "Epoch 3/90\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 52.5356 - accuracy: 0.2683 - val_loss: 27.1198 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 9.90881\n",
      "Epoch 4/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 47.9713 - accuracy: 0.2683 - val_loss: 30.0955 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 9.90881\n",
      "Epoch 5/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 45.1423 - accuracy: 0.3659 - val_loss: 29.2598 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 9.90881\n",
      "Epoch 6/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 41.4480 - accuracy: 0.3171 - val_loss: 26.4098 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 9.90881\n",
      "Epoch 7/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 36.1276 - accuracy: 0.3902 - val_loss: 22.4357 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 9.90881\n",
      "Epoch 8/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 37.7524 - accuracy: 0.3902 - val_loss: 18.7042 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 9.90881\n",
      "Epoch 9/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 33.6412 - accuracy: 0.3902 - val_loss: 15.8107 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 9.90881\n",
      "Epoch 10/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 43.9588 - accuracy: 0.3659 - val_loss: 13.5043 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 9.90881\n",
      "Epoch 11/90\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 35.1897 - accuracy: 0.3659 - val_loss: 11.2761 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 9.90881\n",
      "Epoch 12/90\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 30.9714 - accuracy: 0.2927 - val_loss: 8.6143 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00012: val_loss improved from 9.90881 to 8.61434, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 13/90\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 35.6669 - accuracy: 0.3171 - val_loss: 6.1260 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00013: val_loss improved from 8.61434 to 6.12602, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 14/90\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 15.4950 - accuracy: 0.4878 - val_loss: 4.4565 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00014: val_loss improved from 6.12602 to 4.45647, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 15/90\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 24.8077 - accuracy: 0.3659 - val_loss: 3.8192 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.45647 to 3.81917, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 16/90\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 32.6845 - accuracy: 0.2683 - val_loss: 3.3611 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00016: val_loss improved from 3.81917 to 3.36114, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 17/90\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 26.3216 - accuracy: 0.3902 - val_loss: 2.9393 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.36114 to 2.93932, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 18/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 25.3395 - accuracy: 0.3415 - val_loss: 2.7474 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00018: val_loss improved from 2.93932 to 2.74739, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 19/90\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 31.9392 - accuracy: 0.2927 - val_loss: 2.4842 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00019: val_loss improved from 2.74739 to 2.48423, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 20/90\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 14.2309 - accuracy: 0.3659 - val_loss: 2.6026 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.48423\n",
      "Epoch 21/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 15.2530 - accuracy: 0.4390 - val_loss: 2.6195 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.48423\n",
      "Epoch 22/90\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 15.5393 - accuracy: 0.3659 - val_loss: 2.7254 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.48423\n",
      "Epoch 23/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 16.3567 - accuracy: 0.3902 - val_loss: 2.8781 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.48423\n",
      "Epoch 24/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 19.9418 - accuracy: 0.3902 - val_loss: 3.1470 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.48423\n",
      "Epoch 25/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 14.8257 - accuracy: 0.4634 - val_loss: 3.1102 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.48423\n",
      "Epoch 26/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 24.2999 - accuracy: 0.2683 - val_loss: 3.0979 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.48423\n",
      "Epoch 27/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 21.3939 - accuracy: 0.3415 - val_loss: 3.1964 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.48423\n",
      "Epoch 28/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 15.2314 - accuracy: 0.5366 - val_loss: 3.2793 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.48423\n",
      "Epoch 29/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 19.0974 - accuracy: 0.3415 - val_loss: 3.0863 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.48423\n",
      "Epoch 30/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 16.7411 - accuracy: 0.3415 - val_loss: 2.6598 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.48423\n",
      "Epoch 31/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 14.4945 - accuracy: 0.2683 - val_loss: 2.2015 - val_accuracy: 0.2727\n",
      "\n",
      "Epoch 00031: val_loss improved from 2.48423 to 2.20153, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 32/90\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 14.4752 - accuracy: 0.5122 - val_loss: 1.7719 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00032: val_loss improved from 2.20153 to 1.77189, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 33/90\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 13.9294 - accuracy: 0.4634 - val_loss: 1.5071 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.77189 to 1.50709, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 34/90\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 17.3105 - accuracy: 0.3659 - val_loss: 1.3973 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.50709 to 1.39725, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 35/90\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 10.8342 - accuracy: 0.4390 - val_loss: 1.3421 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.39725 to 1.34206, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 36/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 13.9276 - accuracy: 0.3171 - val_loss: 1.3178 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.34206 to 1.31784, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 37/90\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 14.1884 - accuracy: 0.3171 - val_loss: 1.3911 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.31784\n",
      "Epoch 38/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 15.9441 - accuracy: 0.3659 - val_loss: 1.4687 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.31784\n",
      "Epoch 39/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 11.9131 - accuracy: 0.3902 - val_loss: 1.4773 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.31784\n",
      "Epoch 40/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 11.0892 - accuracy: 0.3659 - val_loss: 1.5282 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.31784\n",
      "Epoch 41/90\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 12.6114 - accuracy: 0.4390 - val_loss: 1.5155 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.31784\n",
      "Epoch 42/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 11.8774 - accuracy: 0.3659 - val_loss: 1.3988 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.31784\n",
      "Epoch 43/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 13.4996 - accuracy: 0.2439 - val_loss: 1.2707 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.31784 to 1.27070, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 44/90\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 13.7217 - accuracy: 0.3415 - val_loss: 1.1629 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.27070 to 1.16286, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 45/90\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10.5195 - accuracy: 0.4146 - val_loss: 1.0721 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.16286 to 1.07208, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 46/90\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 9.7086 - accuracy: 0.4146 - val_loss: 0.9984 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.07208 to 0.99837, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 47/90\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 10.1072 - accuracy: 0.3659 - val_loss: 0.9520 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.99837 to 0.95199, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 48/90\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9.8041 - accuracy: 0.4390 - val_loss: 0.9482 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.95199 to 0.94816, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 49/90\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 7.6941 - accuracy: 0.4390 - val_loss: 0.9560 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.94816\n",
      "Epoch 50/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 10.1125 - accuracy: 0.2683 - val_loss: 0.9845 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.94816\n",
      "Epoch 51/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 12.2501 - accuracy: 0.2439 - val_loss: 0.9724 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.94816\n",
      "Epoch 52/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 10.2687 - accuracy: 0.4146 - val_loss: 0.9715 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.94816\n",
      "Epoch 53/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.7755 - accuracy: 0.4878 - val_loss: 0.9635 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.94816\n",
      "Epoch 54/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 9.6190 - accuracy: 0.3902 - val_loss: 0.9500 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.94816\n",
      "Epoch 55/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.8665 - accuracy: 0.4390 - val_loss: 0.9217 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.94816 to 0.92166, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 56/90\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.1527 - accuracy: 0.5610 - val_loss: 0.8993 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.92166 to 0.89926, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 57/90\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 7.4257 - accuracy: 0.5122 - val_loss: 0.8600 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.89926 to 0.86004, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 58/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 9.5768 - accuracy: 0.4146 - val_loss: 0.8280 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.86004 to 0.82801, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 59/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.5849 - accuracy: 0.4146 - val_loss: 0.7869 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.82801 to 0.78692, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 60/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.9880 - accuracy: 0.5122 - val_loss: 0.7883 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.78692\n",
      "Epoch 61/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 8.3131 - accuracy: 0.4390 - val_loss: 0.7820 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.78692 to 0.78199, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 62/90\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 8.3114 - accuracy: 0.3415 - val_loss: 0.7830 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.78199\n",
      "Epoch 63/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.7937 - accuracy: 0.4878 - val_loss: 0.7726 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.78199 to 0.77261, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 64/90\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.4461 - accuracy: 0.3902 - val_loss: 0.7649 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.77261 to 0.76494, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 65/90\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 7.7941 - accuracy: 0.3415 - val_loss: 0.7745 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.76494\n",
      "Epoch 66/90\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.6341 - accuracy: 0.5122 - val_loss: 0.7682 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.76494\n",
      "Epoch 67/90\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.9463 - accuracy: 0.3902 - val_loss: 0.7500 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.76494 to 0.74997, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 68/90\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.8890 - accuracy: 0.5610 - val_loss: 0.7391 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.74997 to 0.73907, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 69/90\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 6.6817 - accuracy: 0.3902 - val_loss: 0.7431 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.73907\n",
      "Epoch 70/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.0690 - accuracy: 0.3902 - val_loss: 0.7439 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.73907\n",
      "Epoch 71/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.3940 - accuracy: 0.4146 - val_loss: 0.7115 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.73907 to 0.71149, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 72/90\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 5.4555 - accuracy: 0.5366 - val_loss: 0.6884 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.71149 to 0.68840, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 73/90\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 4.9219 - accuracy: 0.5122 - val_loss: 0.6727 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.68840 to 0.67268, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 74/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.6154 - accuracy: 0.4146 - val_loss: 0.6659 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.67268 to 0.66585, saving model to saved_models\\audio_classification.hdf5\n",
      "Epoch 75/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 41ms/step - loss: 7.6949 - accuracy: 0.4146 - val_loss: 0.6786 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.66585\n",
      "Epoch 76/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 5.5166 - accuracy: 0.3659 - val_loss: 0.7002 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.66585\n",
      "Epoch 77/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.1593 - accuracy: 0.5122 - val_loss: 0.7173 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.66585\n",
      "Epoch 78/90\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 6.7899 - accuracy: 0.3902 - val_loss: 0.7307 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.66585\n",
      "Epoch 79/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.8915 - accuracy: 0.4390 - val_loss: 0.7447 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.66585\n",
      "Epoch 80/90\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 3.6255 - accuracy: 0.5610 - val_loss: 0.7553 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.66585\n",
      "Epoch 81/90\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 6.4707 - accuracy: 0.4146 - val_loss: 0.7744 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.66585\n",
      "Epoch 82/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.9700 - accuracy: 0.3902 - val_loss: 0.7975 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.66585\n",
      "Epoch 83/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.8003 - accuracy: 0.4146 - val_loss: 0.8154 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.66585\n",
      "Epoch 84/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.6483 - accuracy: 0.3902 - val_loss: 0.8347 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.66585\n",
      "Epoch 85/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 7.0132 - accuracy: 0.3659 - val_loss: 0.8592 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.66585\n",
      "Epoch 86/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 5.9067 - accuracy: 0.2927 - val_loss: 0.8702 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.66585\n",
      "Epoch 87/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.7021 - accuracy: 0.4634 - val_loss: 0.8704 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.66585\n",
      "Epoch 88/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.2872 - accuracy: 0.5610 - val_loss: 0.8651 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.66585\n",
      "Epoch 89/90\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.4970 - accuracy: 0.4878 - val_loss: 0.8597 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.66585\n",
      "Epoch 90/90\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 4.8542 - accuracy: 0.4390 - val_loss: 0.8589 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.66585\n",
      "Epoch 1/90\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 4.7686 - accuracy: 0.4390 - val_loss: 0.8685 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.66585\n",
      "Epoch 2/90\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 6.8598 - accuracy: 0.2439 - val_loss: 0.8865 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.66585\n",
      "Epoch 3/90\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.7686 - accuracy: 0.5854 - val_loss: 0.9059 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.66585\n",
      "Epoch 4/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.4890 - accuracy: 0.4390 - val_loss: 0.9181 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.66585\n",
      "Epoch 5/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.0779 - accuracy: 0.4634 - val_loss: 0.9251 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.66585\n",
      "Epoch 6/90\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 4.3212 - accuracy: 0.3902 - val_loss: 0.9343 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.66585\n",
      "Epoch 7/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.9882 - accuracy: 0.4634 - val_loss: 0.9408 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.66585\n",
      "Epoch 8/90\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.7127 - accuracy: 0.4878 - val_loss: 0.9441 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.66585\n",
      "Epoch 9/90\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.0639 - accuracy: 0.4146 - val_loss: 0.9484 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.66585\n",
      "Epoch 10/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.4963 - accuracy: 0.3902 - val_loss: 0.9507 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.66585\n",
      "Epoch 11/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.6570 - accuracy: 0.4634 - val_loss: 0.9485 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.66585\n",
      "Epoch 12/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.5131 - accuracy: 0.4146 - val_loss: 0.9493 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.66585\n",
      "Epoch 13/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.3305 - accuracy: 0.4878 - val_loss: 0.9513 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.66585\n",
      "Epoch 14/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.7432 - accuracy: 0.3171 - val_loss: 0.9579 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.66585\n",
      "Epoch 15/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.6079 - accuracy: 0.5366 - val_loss: 0.9611 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.66585\n",
      "Epoch 16/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.1148 - accuracy: 0.4390 - val_loss: 0.9600 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.66585\n",
      "Epoch 17/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.0096 - accuracy: 0.3415 - val_loss: 0.9579 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.66585\n",
      "Epoch 18/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.4957 - accuracy: 0.4146 - val_loss: 0.9517 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.66585\n",
      "Epoch 19/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.7443 - accuracy: 0.6098 - val_loss: 0.9509 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.66585\n",
      "Epoch 20/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.7587 - accuracy: 0.5610 - val_loss: 0.9538 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.66585\n",
      "Epoch 21/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.3362 - accuracy: 0.5366 - val_loss: 0.9541 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.66585\n",
      "Epoch 22/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.8500 - accuracy: 0.4146 - val_loss: 0.9531 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.66585\n",
      "Epoch 23/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.8996 - accuracy: 0.4634 - val_loss: 0.9495 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.66585\n",
      "Epoch 24/90\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.4996 - accuracy: 0.4878 - val_loss: 0.9441 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.66585\n",
      "Epoch 25/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 4.6333 - accuracy: 0.5366 - val_loss: 0.9422 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.66585\n",
      "Epoch 26/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.8866 - accuracy: 0.3902 - val_loss: 0.9387 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.66585\n",
      "Epoch 27/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.5434 - accuracy: 0.5366 - val_loss: 0.9342 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.66585\n",
      "Epoch 28/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 2.1064 - accuracy: 0.6341 - val_loss: 0.9327 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.66585\n",
      "Epoch 29/90\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.0338 - accuracy: 0.6829 - val_loss: 0.9342 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.66585\n",
      "Epoch 30/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.4813 - accuracy: 0.4878 - val_loss: 0.9382 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.66585\n",
      "Epoch 31/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.3365 - accuracy: 0.5122 - val_loss: 0.9496 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.66585\n",
      "Epoch 32/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.0768 - accuracy: 0.6341 - val_loss: 0.9610 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.66585\n",
      "Epoch 33/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.3983 - accuracy: 0.4390 - val_loss: 0.9721 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.66585\n",
      "Epoch 34/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.3506 - accuracy: 0.5122 - val_loss: 0.9910 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.66585\n",
      "Epoch 35/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6231 - accuracy: 0.6585 - val_loss: 1.0147 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.66585\n",
      "Epoch 36/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.5785 - accuracy: 0.4390 - val_loss: 1.0323 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.66585\n",
      "Epoch 37/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.8464 - accuracy: 0.4634 - val_loss: 1.0402 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.66585\n",
      "Epoch 38/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.8701 - accuracy: 0.5122 - val_loss: 1.0432 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.66585\n",
      "Epoch 39/90\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.1958 - accuracy: 0.4146 - val_loss: 1.0438 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.66585\n",
      "Epoch 40/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 2.4625 - accuracy: 0.4634 - val_loss: 1.0418 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.66585\n",
      "Epoch 41/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.2950 - accuracy: 0.5122 - val_loss: 1.0367 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.66585\n",
      "Epoch 42/90\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.7719 - accuracy: 0.5610 - val_loss: 1.0338 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.66585\n",
      "Epoch 43/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.8246 - accuracy: 0.3415 - val_loss: 1.0328 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.66585\n",
      "Epoch 44/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.7253 - accuracy: 0.5122 - val_loss: 1.0350 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.66585\n",
      "Epoch 45/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8385 - accuracy: 0.4390 - val_loss: 1.0358 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.66585\n",
      "Epoch 46/90\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.0262 - accuracy: 0.4390 - val_loss: 1.0377 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.66585\n",
      "Epoch 47/90\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.4239 - accuracy: 0.3902 - val_loss: 1.0396 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.66585\n",
      "Epoch 48/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.5959 - accuracy: 0.4146 - val_loss: 1.0380 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.66585\n",
      "Epoch 49/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.6738 - accuracy: 0.5854 - val_loss: 1.0347 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.66585\n",
      "Epoch 50/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.6013 - accuracy: 0.4634 - val_loss: 1.0327 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.66585\n",
      "Epoch 51/90\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.7215 - accuracy: 0.4634 - val_loss: 1.0301 - val_accuracy: 0.4545\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.66585\n",
      "Epoch 52/90\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.0651 - accuracy: 0.5610 - val_loss: 1.0271 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.66585\n",
      "Epoch 53/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.2270 - accuracy: 0.5854 - val_loss: 1.0262 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.66585\n",
      "Epoch 54/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.4388 - accuracy: 0.3902 - val_loss: 1.0259 - val_accuracy: 0.5455\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.66585\n",
      "Epoch 55/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.9885 - accuracy: 0.4146 - val_loss: 1.0265 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.66585\n",
      "Epoch 56/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.2203 - accuracy: 0.5366 - val_loss: 1.0266 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.66585\n",
      "Epoch 57/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 3.3269 - accuracy: 0.5122 - val_loss: 1.0250 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.66585\n",
      "Epoch 58/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.4031 - accuracy: 0.6341 - val_loss: 1.0229 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.66585\n",
      "Epoch 59/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.4318 - accuracy: 0.5854 - val_loss: 1.0204 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.66585\n",
      "Epoch 60/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8904 - accuracy: 0.5366 - val_loss: 1.0171 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.66585\n",
      "Epoch 61/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0257 - accuracy: 0.6098 - val_loss: 1.0121 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.66585\n",
      "Epoch 62/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.1776 - accuracy: 0.5366 - val_loss: 1.0081 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.66585\n",
      "Epoch 63/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9541 - accuracy: 0.4878 - val_loss: 1.0055 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.66585\n",
      "Epoch 64/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8366 - accuracy: 0.5610 - val_loss: 1.0046 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.66585\n",
      "Epoch 65/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9813 - accuracy: 0.4390 - val_loss: 1.0038 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.66585\n",
      "Epoch 66/90\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.1150 - accuracy: 0.5122 - val_loss: 1.0042 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.66585\n",
      "Epoch 67/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0178 - accuracy: 0.6098 - val_loss: 1.0045 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.66585\n",
      "Epoch 68/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0184 - accuracy: 0.6829 - val_loss: 1.0044 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.66585\n",
      "Epoch 69/90\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 3.0998 - accuracy: 0.4146 - val_loss: 1.0056 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.66585\n",
      "Epoch 70/90\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.7087 - accuracy: 0.4878 - val_loss: 1.0071 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.66585\n",
      "Epoch 71/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 1.6820 - accuracy: 0.5854 - val_loss: 1.0076 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.66585\n",
      "Epoch 72/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.4226 - accuracy: 0.4146 - val_loss: 1.0060 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.66585\n",
      "Epoch 73/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.3707 - accuracy: 0.4634 - val_loss: 1.0042 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.66585\n",
      "Epoch 74/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.7180 - accuracy: 0.5854 - val_loss: 1.0044 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.66585\n",
      "Epoch 75/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9610 - accuracy: 0.5854 - val_loss: 1.0061 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.66585\n",
      "Epoch 76/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2210 - accuracy: 0.6098 - val_loss: 1.0064 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.66585\n",
      "Epoch 77/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.8445 - accuracy: 0.4878 - val_loss: 1.0059 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.66585\n",
      "Epoch 78/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.4837 - accuracy: 0.5122 - val_loss: 1.0068 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.66585\n",
      "Epoch 79/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.6367 - accuracy: 0.6585 - val_loss: 1.0090 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.66585\n",
      "Epoch 80/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.7608 - accuracy: 0.5610 - val_loss: 1.0110 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.66585\n",
      "Epoch 81/90\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9700 - accuracy: 0.4878 - val_loss: 1.0135 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.66585\n",
      "Epoch 82/90\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.3133 - accuracy: 0.6098 - val_loss: 1.0153 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.66585\n",
      "Epoch 83/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.4529 - accuracy: 0.4390 - val_loss: 1.0159 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.66585\n",
      "Epoch 84/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7774 - accuracy: 0.4878 - val_loss: 1.0156 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.66585\n",
      "Epoch 85/90\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7428 - accuracy: 0.4146 - val_loss: 1.0142 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.66585\n",
      "Epoch 86/90\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.8078 - accuracy: 0.4878 - val_loss: 1.0129 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.66585\n",
      "Epoch 87/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.0474 - accuracy: 0.5122 - val_loss: 1.0094 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.66585\n",
      "Epoch 88/90\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.2048 - accuracy: 0.4634 - val_loss: 1.0042 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.66585\n",
      "Epoch 89/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1271 - accuracy: 0.6098 - val_loss: 1.0009 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.66585\n",
      "Epoch 90/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.0197 - accuracy: 0.4390 - val_loss: 0.9985 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.66585\n",
      "Epoch 1/90\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 1.6538 - accuracy: 0.4634 - val_loss: 0.9938 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.66585\n",
      "Epoch 2/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5125 - accuracy: 0.5122 - val_loss: 0.9895 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.66585\n",
      "Epoch 3/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7807 - accuracy: 0.4390 - val_loss: 0.9881 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.66585\n",
      "Epoch 4/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.9991 - accuracy: 0.5854 - val_loss: 0.9903 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.66585\n",
      "Epoch 5/90\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0727 - accuracy: 0.6585 - val_loss: 0.9942 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.66585\n",
      "Epoch 6/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.7705 - accuracy: 0.4634 - val_loss: 0.9968 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.66585\n",
      "Epoch 7/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0313 - accuracy: 0.5854 - val_loss: 0.9996 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.66585\n",
      "Epoch 8/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3976 - accuracy: 0.6341 - val_loss: 0.9996 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.66585\n",
      "Epoch 9/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1878 - accuracy: 0.5122 - val_loss: 0.9978 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.66585\n",
      "Epoch 10/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.9439 - accuracy: 0.6585 - val_loss: 0.9962 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.66585\n",
      "Epoch 11/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9599 - accuracy: 0.6585 - val_loss: 0.9942 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.66585\n",
      "Epoch 12/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3754 - accuracy: 0.5122 - val_loss: 0.9916 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.66585\n",
      "Epoch 13/90\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.3040 - accuracy: 0.5854 - val_loss: 0.9881 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.66585\n",
      "Epoch 14/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6539 - accuracy: 0.4634 - val_loss: 0.9830 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.66585\n",
      "Epoch 15/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.9813 - accuracy: 0.4634 - val_loss: 0.9770 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.66585\n",
      "Epoch 16/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2915 - accuracy: 0.5610 - val_loss: 0.9705 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.66585\n",
      "Epoch 17/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2740 - accuracy: 0.5122 - val_loss: 0.9627 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.66585\n",
      "Epoch 18/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.5456 - accuracy: 0.6341 - val_loss: 0.9556 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.66585\n",
      "Epoch 19/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0945 - accuracy: 0.6341 - val_loss: 0.9490 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.66585\n",
      "Epoch 20/90\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0203 - accuracy: 0.6341 - val_loss: 0.9445 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.66585\n",
      "Epoch 21/90\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.5043 - accuracy: 0.5610 - val_loss: 0.9386 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.66585\n",
      "Epoch 22/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6461 - accuracy: 0.5122 - val_loss: 0.9313 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.66585\n",
      "Epoch 23/90\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.6881 - accuracy: 0.4634 - val_loss: 0.9262 - val_accuracy: 0.6364\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023: val_loss did not improve from 0.66585\n",
      "Epoch 24/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0986 - accuracy: 0.6098 - val_loss: 0.9234 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.66585\n",
      "Epoch 25/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8674 - accuracy: 0.5122 - val_loss: 0.9204 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.66585\n",
      "Epoch 26/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6131 - accuracy: 0.4634 - val_loss: 0.9184 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.66585\n",
      "Epoch 27/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1619 - accuracy: 0.6341 - val_loss: 0.9178 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.66585\n",
      "Epoch 28/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.8702 - accuracy: 0.7073 - val_loss: 0.9188 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.66585\n",
      "Epoch 29/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.9699 - accuracy: 0.5610 - val_loss: 0.9168 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.66585\n",
      "Epoch 30/90\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7649 - accuracy: 0.4634 - val_loss: 0.9139 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.66585\n",
      "Epoch 31/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1563 - accuracy: 0.5366 - val_loss: 0.9110 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.66585\n",
      "Epoch 32/90\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.1996 - accuracy: 0.5610 - val_loss: 0.9071 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.66585\n",
      "Epoch 33/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.3000 - accuracy: 0.5854 - val_loss: 0.9040 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.66585\n",
      "Epoch 34/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.7192 - accuracy: 0.5122 - val_loss: 0.9040 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.66585\n",
      "Epoch 35/90\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8747 - accuracy: 0.6341 - val_loss: 0.9109 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.66585\n",
      "Epoch 36/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2408 - accuracy: 0.5610 - val_loss: 0.9188 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.66585\n",
      "Epoch 37/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.2012 - accuracy: 0.6341 - val_loss: 0.9257 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.66585\n",
      "Epoch 38/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.6757 - accuracy: 0.6341 - val_loss: 0.9281 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.66585\n",
      "Epoch 39/90\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.3913 - accuracy: 0.5366 - val_loss: 0.9277 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.66585\n",
      "Epoch 40/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4701 - accuracy: 0.4634 - val_loss: 0.9301 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.66585\n",
      "Epoch 41/90\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0397 - accuracy: 0.5366 - val_loss: 0.9307 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.66585\n",
      "Epoch 42/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5131 - accuracy: 0.7561 - val_loss: 0.9295 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.66585\n",
      "Epoch 43/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9062 - accuracy: 0.6098 - val_loss: 0.9289 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.66585\n",
      "Epoch 44/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1286 - accuracy: 0.5366 - val_loss: 0.9284 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.66585\n",
      "Epoch 45/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1482 - accuracy: 0.5854 - val_loss: 0.9287 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.66585\n",
      "Epoch 46/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0379 - accuracy: 0.5366 - val_loss: 0.9284 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.66585\n",
      "Epoch 47/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0112 - accuracy: 0.6341 - val_loss: 0.9217 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.66585\n",
      "Epoch 48/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.9589 - accuracy: 0.6341 - val_loss: 0.9152 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.66585\n",
      "Epoch 49/90\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9612 - accuracy: 0.5366 - val_loss: 0.9077 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.66585\n",
      "Epoch 50/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.3373 - accuracy: 0.6341 - val_loss: 0.9006 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.66585\n",
      "Epoch 51/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.3872 - accuracy: 0.5610 - val_loss: 0.8927 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.66585\n",
      "Epoch 52/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9888 - accuracy: 0.6098 - val_loss: 0.8838 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.66585\n",
      "Epoch 53/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.9370 - accuracy: 0.6341 - val_loss: 0.8739 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.66585\n",
      "Epoch 54/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6266 - accuracy: 0.6829 - val_loss: 0.8702 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.66585\n",
      "Epoch 55/90\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0178 - accuracy: 0.5854 - val_loss: 0.8677 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.66585\n",
      "Epoch 56/90\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.9316 - accuracy: 0.5366 - val_loss: 0.8663 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.66585\n",
      "Epoch 57/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7278 - accuracy: 0.6585 - val_loss: 0.8648 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.66585\n",
      "Epoch 58/90\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8101 - accuracy: 0.6098 - val_loss: 0.8609 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.66585\n",
      "Epoch 59/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8629 - accuracy: 0.6341 - val_loss: 0.8587 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.66585\n",
      "Epoch 60/90\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.8901 - accuracy: 0.6585 - val_loss: 0.8605 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.66585\n",
      "Epoch 61/90\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7866 - accuracy: 0.6098 - val_loss: 0.8641 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.66585\n",
      "Epoch 62/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.3394 - accuracy: 0.6829 - val_loss: 0.8685 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.66585\n",
      "Epoch 63/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7702 - accuracy: 0.5854 - val_loss: 0.8733 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.66585\n",
      "Epoch 64/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0211 - accuracy: 0.5610 - val_loss: 0.8764 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.66585\n",
      "Epoch 65/90\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.8587 - accuracy: 0.6829 - val_loss: 0.8785 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.66585\n",
      "Epoch 66/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2410 - accuracy: 0.6098 - val_loss: 0.8790 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.66585\n",
      "Epoch 67/90\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.8671 - accuracy: 0.7073 - val_loss: 0.8779 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.66585\n",
      "Epoch 68/90\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.1982 - accuracy: 0.5366 - val_loss: 0.8763 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.66585\n",
      "Epoch 69/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7830 - accuracy: 0.6829 - val_loss: 0.8724 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.66585\n",
      "Epoch 70/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0567 - accuracy: 0.6098 - val_loss: 0.8723 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.66585\n",
      "Epoch 71/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.5093 - accuracy: 0.5854 - val_loss: 0.8721 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.66585\n",
      "Epoch 72/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0746 - accuracy: 0.5610 - val_loss: 0.8681 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.66585\n",
      "Epoch 73/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0236 - accuracy: 0.6098 - val_loss: 0.8608 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.66585\n",
      "Epoch 74/90\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5339 - accuracy: 0.7805 - val_loss: 0.8567 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.66585\n",
      "Epoch 75/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.1739 - accuracy: 0.7317 - val_loss: 0.8547 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.66585\n",
      "Epoch 76/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.9984 - accuracy: 0.7805 - val_loss: 0.8505 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.66585\n",
      "Epoch 77/90\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.6762 - accuracy: 0.5366 - val_loss: 0.8475 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.66585\n",
      "Epoch 78/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.9877 - accuracy: 0.6098 - val_loss: 0.8432 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.66585\n",
      "Epoch 79/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6095 - accuracy: 0.7561 - val_loss: 0.8383 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.66585\n",
      "Epoch 80/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5722 - accuracy: 0.7561 - val_loss: 0.8334 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.66585\n",
      "Epoch 81/90\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7843 - accuracy: 0.6098 - val_loss: 0.8269 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.66585\n",
      "Epoch 82/90\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5165 - accuracy: 0.8293 - val_loss: 0.8215 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.66585\n",
      "Epoch 83/90\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7425 - accuracy: 0.6829 - val_loss: 0.8159 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.66585\n",
      "Epoch 84/90\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.8265 - accuracy: 0.6585 - val_loss: 0.8082 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.66585\n",
      "Epoch 85/90\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3372 - accuracy: 0.6829 - val_loss: 0.8015 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.66585\n",
      "Epoch 86/90\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7580 - accuracy: 0.6098 - val_loss: 0.7930 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.66585\n",
      "Epoch 87/90\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6869 - accuracy: 0.7073 - val_loss: 0.7862 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.66585\n",
      "Epoch 88/90\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8313 - accuracy: 0.6829 - val_loss: 0.7801 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.66585\n",
      "Epoch 89/90\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5738 - accuracy: 0.7317 - val_loss: 0.7747 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.66585\n",
      "Epoch 90/90\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5938 - accuracy: 0.7073 - val_loss: 0.7687 - val_accuracy: 0.6364\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.66585\n",
      "Training completed in time:  0:00:18.369081\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 90\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', verbose=1, save_best_only=True)\n",
    "    \n",
    "start = datetime.now()\n",
    "for i in range(3):\n",
    "    model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "    duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c920168e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363636255264282\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53195353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_x=model.predict(X_test)\n",
    "classes_x=np.argmax(predict_x,axis=1)\n",
    "classes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dd56bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd0ae2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.4550470e+02  7.6165222e+01  7.2084670e+00  2.1746096e+01\n",
      "  1.3013437e+00  1.2874533e+01 -8.1447582e+00  3.6055577e+00\n",
      " -2.8527455e+00  2.6408575e+00 -8.1880951e+00  6.0818607e-01\n",
      " -4.3710408e+00  1.5807701e+00 -2.7393231e+00 -1.9911110e+00\n",
      " -3.6566839e+00  5.5628427e-04 -3.5904982e+00 -1.7349663e+00\n",
      " -3.3976362e+00 -4.1261415e+00 -1.3746802e+00 -4.4973626e+00\n",
      " -1.7397245e+00  8.8191259e-01  4.5868063e+00  2.7416987e+00\n",
      "  3.5085616e+00  2.0790579e+00  1.6184493e+00  1.5413741e+00\n",
      "  9.6752703e-01 -1.7651465e-02 -1.9381401e-01  2.0345204e+00\n",
      "  3.0008860e+00  3.5064609e+00  1.1102633e+00  2.2798288e+00]\n",
      "[[-5.4550470e+02  7.6165222e+01  7.2084670e+00  2.1746096e+01\n",
      "   1.3013437e+00  1.2874533e+01 -8.1447582e+00  3.6055577e+00\n",
      "  -2.8527455e+00  2.6408575e+00 -8.1880951e+00  6.0818607e-01\n",
      "  -4.3710408e+00  1.5807701e+00 -2.7393231e+00 -1.9911110e+00\n",
      "  -3.6566839e+00  5.5628427e-04 -3.5904982e+00 -1.7349663e+00\n",
      "  -3.3976362e+00 -4.1261415e+00 -1.3746802e+00 -4.4973626e+00\n",
      "  -1.7397245e+00  8.8191259e-01  4.5868063e+00  2.7416987e+00\n",
      "   3.5085616e+00  2.0790579e+00  1.6184493e+00  1.5413741e+00\n",
      "   9.6752703e-01 -1.7651465e-02 -1.9381401e-01  2.0345204e+00\n",
      "   3.0008860e+00  3.5064609e+00  1.1102633e+00  2.2798288e+00]]\n",
      "(1, 40)\n",
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Deepika'], dtype='<U8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"Deepika_test.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast')\n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=model.predict(mfccs_scaled_features)\n",
    "predicted_label=np.argmax(predicted_label,axis=1)\n",
    "print(predicted_label)\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ba5aec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#ProjectGurukul's Voice recorder\n",
    "#Import necessary modules\n",
    "import sounddevice as sd\n",
    "from tkinter import *\n",
    "import queue\n",
    "import soundfile as sf\n",
    "import threading\n",
    "from tkinter import messagebox\n",
    "from pydub import AudioSegment \n",
    "from pydub.utils import make_chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1844e4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting 0.wav\n",
      "exporting 1.wav\n",
      "exporting 2.wav\n",
      "The list after removing duplicates : [array(['Deepika'], dtype='<U8')]\n"
     ]
    }
   ],
   "source": [
    "#Functions to play, stop and record audio in Python voice recorder\n",
    "#The recording is done as a thread to prevent it being the main process\n",
    "def threading_rec(x):\n",
    "   if x == 1:\n",
    "       #If recording is selected, then the thread is activated\n",
    "       t1=threading.Thread(target= record_audio)\n",
    "       t1.start()\n",
    "   elif x == 2:\n",
    "       #To stop, set the flag to false\n",
    "       global recording\n",
    "       recording = False\n",
    "       messagebox.showinfo(message=\"Recording finished\")\n",
    "   elif x == 3:\n",
    "       #To play a recording, it must exist.\n",
    "       if file_exists:\n",
    "           #Read the recording if it exists and play it\n",
    "           data, fs = sf.read(\"trial.wav\", dtype='float32')\n",
    "           sd.play(data,fs)\n",
    "           sd.wait()\n",
    "       else:\n",
    "           #Display and error if none is found\n",
    "           messagebox.showerror(message=\"Record something to play\")\n",
    "#Fit data into queue\n",
    "def callback(indata, frames, time, status):\n",
    "   q.put(indata.copy())\n",
    "\n",
    "\n",
    "#Recording function\n",
    "def record_audio():\n",
    "   #Declare global variables   \n",
    "   global recording\n",
    "   #Set to True to record\n",
    "   recording= True  \n",
    "   global file_exists\n",
    "   #Create a file to save the audio\n",
    "   messagebox.showinfo(message=\"Recording Audio. Speak into the mic\")\n",
    "   with sf.SoundFile(\"trial.wav\", mode='w', samplerate=44100,\n",
    "                       channels=2) as file:\n",
    "   #Create an input stream to record audio without a preset time\n",
    "           with sd.InputStream(samplerate=44100, channels=2, callback=callback):\n",
    "               while recording == True:\n",
    "                   #Set the variable to True to allow playing the audio later\n",
    "                   file_exists =True\n",
    "                   #write into file\n",
    "                   file.write(q.get())\n",
    "def my_function(x):\n",
    "  return list(dict.fromkeys(x))\n",
    "\n",
    "                \n",
    "def fun():\n",
    "    array=[]\n",
    "    \n",
    "\n",
    "    myaudio = AudioSegment.from_file(\"trial.wav\", \"wav\")\n",
    "    chunk_length_ms = 4000 # pydub calculates in millisec\n",
    "    chunks = make_chunks(myaudio,chunk_length_ms) #Make chunks of one sec\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_name = \"{0}.wav\".format(i)\n",
    "        print (\"exporting\", chunk_name)\n",
    "        chunk.export('splitted/'+chunk_name, format=\"wav\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_name = \"splitted/{0}.wav\".format(i)\n",
    "        filename=chunk_name\n",
    "        audio, sample_rate = librosa.load(filename, res_type='kaiser_fast')\n",
    "        mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "        mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "        predicted_label=model.predict(mfccs_scaled_features)\n",
    "        predicted_label=np.argmax(predicted_label,axis=1)\n",
    "        prediction_class = labelencoder.inverse_transform(predicted_label)\n",
    "        array.append(prediction_class)\n",
    "        #Label(voice_rec, text=prediction_class, bg=\"#107dc2\").grid(row=4, column=0, columnspan=3)\n",
    "    #removal of duplicate names    \n",
    "    res = []\n",
    "    [res.append(x) for x in array if x not in res]\n",
    "  \n",
    "    # printing list after removal \n",
    "    print (\"The list after removing duplicates : \" + str(res))\n",
    "    with open('your_file.txt', 'w') as f:\n",
    "        for item in res:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "                \n",
    "#Define the user interface for Voice Recorder using Python\n",
    "voice_rec = Tk()\n",
    "voice_rec.geometry(\"360x200\")\n",
    "voice_rec.title(\"Voice Recorder\")\n",
    "voice_rec.config(bg=\"#107dc2\")\n",
    "#Create a queue to contain the audio data\n",
    "q = queue.Queue()\n",
    "#Declare variables and initialise them\n",
    "recording = False\n",
    "file_exists = False\n",
    "\n",
    "#Label to display app title in Python Voice Recorder Project\n",
    "title_lbl  = Label(voice_rec, text=\"Audio Classifier\", bg=\"#107dc2\").grid(row=0, column=0, columnspan=3)\n",
    " \n",
    "#Button to record audio\n",
    "record_btn = Button(voice_rec, text=\"Record Audio\", command=lambda m=1:threading_rec(m))\n",
    "#Stop button\n",
    "stop_btn = Button(voice_rec, text=\"Stop Recording\", command=lambda m=2:threading_rec(m))\n",
    "\n",
    "#Play button\n",
    "play_btn = Button(voice_rec, text=\"Play Recording\", command=lambda m=3:threading_rec(m))\n",
    "\n",
    "pred_btn=Button(voice_rec,text=\"Predict class\",command=fun)\n",
    "#Position buttons\n",
    "record_btn.grid(row=1,column=1)\n",
    "stop_btn.grid(row=1,column=0)\n",
    "play_btn.grid(row=1,column=2)\n",
    "pred_btn.grid(row=3,column=1)\n",
    "\n",
    "\n",
    "voice_rec.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e65d1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
